# Evidence Scoring System

**Document:** Systemic Immunity — Evidence Quality Framework  
**Based on:** Admiralty System (NATO STANAG 2511) adapted for policy research  
**Purpose:** Standardized evaluation of claims and evidence in the Comprehensive Report

---

## Theoretical Foundation

This scoring system adapts the **Admiralty System**, developed by British Naval Intelligence in 1939 and now codified in NATO STANAG 2511. The system has been used for 80+ years by military, intelligence, and law enforcement agencies worldwide.

### Core Principle: Separate Source from Information

The Admiralty System's key insight is that **source reliability and information credibility must be evaluated independently**:

- Valuable information can come from unreliable sources
- Disinformation can come from usually-reliable sources
- The same source can be highly reliable on one topic and unreliable on another

This separation prevents both unwarranted dismissal of inconvenient evidence and uncritical acceptance of claims from "trusted" sources.

---

## Axis 1: Source Type Rating

Evaluates the **inherent reliability** of the source category.

| Rating | Source Type | Description | Examples |
|--------|-------------|-------------|----------|
| **A** | Primary Legal/Government | Original documents with legal standing | Contract text, court decisions, legislation, FOIL responses, official transcripts |
| **B** | Official Statistics | Government-produced quantitative data | DOCCS reports, Comptroller audits, Inspector General reports, AG annual reports |
| **C** | Credentialed Journalism | Professional investigative reporting with editorial standards | Marshall Project, New York Times, documented interviews |
| **D** | Advocacy/Stakeholder | Organizations with stated positions | CANY testimony, NYCLU reports, union statements, attorney guidance |
| **E** | Secondary/Derived | Analysis built on other sources | Calculated statistics, pattern analysis, cross-referenced databases |
| **F** | Cannot Verify | Source unavailable or unidentified | Undocumented claims, broken links, unattributed statements |

### Guidance Notes

1. **A-rated sources** require no corroboration for factual claims (e.g., contract language)
2. **B-rated sources** should be checked for methodology but are presumptively accurate
3. **C-rated sources** require fact-checking of specific claims but are generally reliable
4. **D-rated sources** represent legitimate perspectives but have advocacy interests
5. **E-rated sources** depend entirely on the quality of underlying data
6. **F-rated sources** should be flagged for verification or removal

---

## Axis 2: Information Confidence Rating

Evaluates the **credibility of the specific claim**, independent of source type.

| Rating | Confidence Level | Criteria |
|--------|------------------|----------|
| **1** | Confirmed | Multiple independent sources confirm; quantified with data; verifiable by reader |
| **2** | Probable | Two or more sources; consistent pattern; minor discrepancies explained |
| **3** | Possible | Single credible source; logically plausible; fits known patterns |
| **4** | Doubtful | Weak sourcing; contradicted by other evidence; requires qualification |
| **5** | Speculative | Inference or extrapolation; no direct evidence; hypothesis |
| **6** | Cannot Judge | Insufficient information to evaluate; flagged for research |

### Guidance Notes

1. **Rating 1** claims can be stated as fact
2. **Rating 2** claims can be stated with high confidence ("evidence shows...")
3. **Rating 3** claims should be qualified ("according to..." or "testimony indicates...")
4. **Rating 4** claims should be explicitly flagged as uncertain
5. **Rating 5** claims should be labeled as inferences or hypotheses
6. **Rating 6** claims should be investigated or removed

---

## Composite Scoring

Combine both axes for a complete evaluation:

| Score | Interpretation | Action |
|-------|----------------|--------|
| **A1, A2, B1** | Gold standard | State as established fact |
| **B2, C1, C2** | Strong evidence | State with confidence |
| **A3, B3, C3, D1, D2** | Adequate evidence | State with attribution |
| **D3, E1, E2** | Moderate evidence | State with qualification |
| **D4, E3, E4** | Weak evidence | Flag for strengthening or qualify heavily |
| **Any 5 or 6, Any F** | Insufficient | Investigate, qualify as speculation, or remove |

---

## Application Examples

| Claim | Source | Score | Rationale |
|-------|--------|-------|-----------|
| "Article 8 replaces Civil Service Law §75" | SSU Contract text + Kuhnel court decision | **A1** | Primary legal documents; confirmed by court |
| "75% of terminated officers are reinstated" | Marshall Project analysis of arbitration data | **C2** | Credentialed journalism; methodology documented |
| "OSI systematically downgrades complaints" | CANY legislative testimony | **D3** | Advocacy source; plausible but not quantified |
| "40% increase in misconduct from collective bargaining" | University of Chicago peer-reviewed study | **B1** | Official academic research; peer-reviewed methodology |
| "True accountability rate is 1-2%" | Derived from multiple filtering stages | **E3** | Calculated inference; depends on assumptions |
| "Officers coordinate testimony" | Logical inference from disclosure rules | **E4** | Inference; no direct documentation of coordination |

---

## Scoring Process

For each argument in the Argument Map:

1. **Identify the claim** — What specifically is being asserted?
2. **Identify the source(s)** — What evidence supports this claim?
3. **Rate the source type (A-F)** — Based on source category
4. **Rate information confidence (1-6)** — Based on verification criteria
5. **Assign composite score** — Combine both ratings
6. **Determine action** — Based on composite interpretation
7. **Document gaps** — Note what additional evidence would strengthen the claim

---

## Quality Thresholds

For the Comprehensive Report, we establish the following standards:

| Claim Type | Minimum Score | Rationale |
|------------|---------------|-----------|
| **Core thesis statements** | B2 or higher | Central arguments must be strongly supported |
| **Statistical claims** | B1 or A2 | Numbers require official or primary sources |
| **Causal claims** | C2 or higher | Causation requires multiple confirming sources |
| **Descriptive claims** | C3 or higher | Descriptions can rely on single credible source |
| **Inferences** | E3 with explicit label | Must be clearly marked as inference |

Claims falling below these thresholds should be:
- Strengthened with additional evidence
- Qualified with appropriate hedging language
- Moved to a "requires further research" category
- Removed if unverifiable

---

## Limitations

This scoring system has known limitations:

1. **Subjectivity** — Ratings involve judgment calls
2. **Source category overlap** — Some sources fit multiple categories
3. **Confirmation bias** — Evaluators may rate confirming evidence higher
4. **Dynamic reliability** — Sources can be reliable on one topic, unreliable on another

To mitigate these limitations:
- Document reasoning for each rating
- Flag borderline cases for discussion
- Seek independent review of critical claims
- Update ratings as new evidence emerges

---

## References

- NATO STANAG 2511: Allied Joint Doctrine for Intelligence Procedures (AJP-2.1)
- McLachlan, D. (1968). *Room 39: A Study in Naval Intelligence*
- GRADE Working Group. (2004-present). Grading of Recommendations Assessment, Development and Evaluation
- Blockint. (2021). "The origin of information grading systems"

